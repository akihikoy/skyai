// agent file for maze2d task
// NOTE: lmanager and environment must be defined in this file
// TEST of avf_linear whose available action set changes with state

module  MBasicLearningManager                                 , lmanager
module  MMazeEnvironment                                      , environment
module  MBasisFunctionsNGnet                                  , ngnet
module  MAVFLinearDiscAction                                  , avf_linear
module  MRadialActionSpace2                                   , action_space
module  MDiscretizer                                          , action_discretizer
module  MNavigationTask                                       , task
module  MRemoveSignalArguments_TInt                           , exec_action
module  MRewardAccumulator                                    , rwd_accumulator
module  MTDGenericFuncApprox_TDiscreteAction                  , behavior
module  MTimedResourceXX_TRealVector                          , tr_state
module  MTimedResourceXY_TRealVector_TRealVector              , tr_ngnet
module  MUserEmittedTimer                                     , timer
module  MSimpleDataLogger2_TInt_TReal                         , logger_eps_return
module  MUniversalDataLogger                                  , logger_action_result
module  MHolder_TRealVector                                   , holder_action
module  MIntToBoolVectorMapper                                , situation_to_actionset

/// initialization process:
connect  lmanager.signal_initialization                ,environment.slot_initialize
connect  lmanager.signal_initialization                ,task.slot_initialize
connect  lmanager.signal_initialization                ,situation_to_actionset.slot_reset
connect  lmanager.signal_initialization                ,ngnet.slot_initialize
connect  ngnet.slot_initialize_finished                ,action_space.slot_initialize
connect  ngnet.slot_initialize_finished                ,action_discretizer.slot_initialize
connect  action_discretizer.slot_initialize_finished   ,avf_linear.slot_initialize
connect  avf_linear.slot_initialize_finished           ,behavior.slot_initialize
connect  lmanager.signal_initialization                ,logger_eps_return.slot_initialize
connect  lmanager.signal_initialization                ,logger_action_result.slot_initialize

/// start of episode process:
connect  lmanager.signal_start_of_episode              ,tr_ngnet.slot_reset
connect  tr_ngnet.slot_reset_finished                  ,tr_state.slot_reset
connect  tr_state.slot_reset_finished                  ,timer.slot_reset
connect  timer.slot_reset_finished                     ,environment.slot_start_episode
connect  environment.slot_start_episode_finished       ,behavior.slot_start_episode
connect  environment.slot_start_episode_finished       ,task.slot_start_episode
connect  environment.slot_start_episode_finished       ,avf_linear.slot_reset

/// start of time step process:
connect  environment.signal_start_of_timestep          ,timer.slot_start_step
connect  timer.signal_start_of_step                    ,action_space.slot_start_time_step

/// end of time step process:
connect  environment.signal_end_of_timestep            ,timer.slot_finish_step
connect  timer.signal_end_of_step                      ,task.slot_finish_time_step
connect  task.slot_finish_time_step_finished           ,action_space.slot_finish_time_step

/// learning signals:
connect  behavior.signal_execute_action                ,action_discretizer.slot_in
connect  action_discretizer.signal_out                 ,action_space.slot_execute_action
connect  behavior.signal_execute_action                ,exec_action.slot_in
connect  exec_action.signal_out                        ,rwd_accumulator.slot_reset
connect  action_space.signal_execute_command           ,environment.slot_execute_command
connect  action_space.signal_execute_command           ,holder_action.slot_1
connect  action_space.signal_end_of_action             ,behavior.slot_finish_action
connect  behavior.signal_avf_add_to_parameter          ,avf_linear.slot_add_to_parameter
connect  behavior.signal_end_of_action                 ,logger_action_result.slot_log

connect  task.signal_goal_reward                       ,rwd_accumulator.slot_add
connect  environment.signal_system_reward              ,rwd_accumulator.slot_add

connect  environment.signal_end_of_episode             ,behavior.slot_finish_episode
connect  task.signal_end_of_episode                    ,behavior.slot_finish_episode

connect  behavior.signal_end_of_episode                ,logger_eps_return.slot_log
connect  logger_eps_return.slot_log_finished           ,logger_action_result.slot_newline
connect  logger_action_result.slot_newline_finished    ,lmanager.slot_finish_episode

/// I/O:
connect  action_discretizer.out_set_size               ,avf_linear.in_action_set_size
connect  environment.out_situation                     ,situation_to_actionset.in_1
connect  situation_to_actionset.out_1                  ,avf_linear.in_action_availability
connect  rwd_accumulator.out_sum                       ,behavior.in_reward
connect  environment.out_position                      ,tr_state.in_x
connect  ngnet.out_f2                                  ,tr_ngnet.in_converter
connect  tr_state.out_x                                ,task.in_position
connect  timer.out_disc_time                           ,tr_ngnet.in_disc_time
connect  timer.out_disc_time                           ,tr_state.in_disc_time
connect  tr_state.out_x                                ,tr_ngnet.in_x

connect  tr_ngnet.out_y                                ,avf_linear.in_feature
connect  lmanager.out_episode_number                   ,avf_linear.in_episode_number
connect  avf_linear.out_select_action            ,behavior.in_avf_select_action
connect  avf_linear.out_replacing_trace          ,behavior.in_avf_replacing_trace
connect  avf_linear.out_create_parameter         ,behavior.in_avf_create_parameter
connect  avf_linear.out_zero_parameter           ,behavior.in_avf_zero_parameter

connect  lmanager.out_episode_number                   ,logger_eps_return.in_data1
connect  behavior.out_return_in_episode                ,logger_eps_return.in_data2

connect  lmanager.out_episode_number                   ,logger_action_result.in_data_int
connect  timer.out_cont_time                           ,logger_action_result.in_data_real
connect  rwd_accumulator.out_last_accessed             ,logger_action_result.in_data_real
connect  behavior.out_td_error                         ,logger_action_result.in_data_real
connect  behavior.out_current_action_value             ,logger_action_result.in_data_real
connect  tr_state.out_x                                ,logger_action_result.in_data_real_vector
connect  holder_action.out_1                           ,logger_action_result.in_data_real_vector


/// parameter setting:

lmanager.config ={
    MaxEpisodeNumber = 1000
    RandomSeed = "0"
  }

task.config ={
    MaxTime = 100
  }

behavior.config={
    UsingEligibilityTrace = true
    Alpha = 0.7
    AlphaDecreasingFactor = 0.002
    Lambda = 0.9
  }

action_discretizer.config ={
    Min = (-3.14159265, 0.03, 0.1)
    Max = (3.14159265, 0.03, 0.1)
    Division = (17, 1, 1)
  }
situation_to_actionset.config={
    Size = 17
    TrueSet ={
        [0]= "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16"
        [1]= "0 4 8 12"
      }
  }


ngnet.config={
    NGnetFileName = "materials/ngnet222g.dat"
  }

avf_linear.config={
    ActionSelection = "asBoltzman"
    PolicyImprovement = "piExpReduction"
    Tau = 0.1
    TauDecreasingFactor = 0.005
    TraceMax = 1.0
  }

logger_eps_return.config={
    FileName = "XXXRESDIR/log-eps-ret.dat"
  }

logger_action_result.config ={
    FileName = "XXXRESDIR/log-action-res.dat"
    OrderOfColumns ={
        ["lmanager.out_episode_number"]= 1
        ["timer.out_cont_time"]= 2
        ["rwd_accumulator.out_last_accessed"]= 4
        ["behavior.out_td_error"]= 5
        ["behavior.out_current_action_value"]= 6
        ["tr_state.out_x"]= 8
        ["holder_action.out_1"]= 10
      }
    PutBlankData = true
  }
