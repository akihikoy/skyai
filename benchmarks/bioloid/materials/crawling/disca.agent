// agent file for motion learning task of manoi01 (common for disc-action behavior module)

//TODO include crawling/cmn.agent

module  MAVFLinearDiscAction                                   , avf_linear
module  MRemoveSignalArguments_TInt                            , exec_action
module  MTDGenericFuncApprox_TDiscreteAction                   , behavior

/// initialization process:
connect  avf_linear.slot_initialize_finished            , behavior.slot_initialize

/// start of episode process:
connect  environment.slot_start_episode_finished        , behavior.slot_start_episode
connect  environment.slot_start_episode_finished        , task.slot_start_episode
connect  environment.slot_start_episode_finished        , avf_linear.slot_reset

/// start of time step process:

/// end of time step process:

/// learning signals:
connect  behavior.signal_execute_action                 , exec_action.slot_in
connect  exec_action.signal_out                         , rwd_accumulator.slot_reset
connect  exec_action.signal_out                         , damage_reward.slot_reset

connect  behavior.signal_avf_add_to_parameter           , avf_linear.slot_add_to_parameter
connect  behavior.signal_end_of_action                  , logger_action_result.slot_log

connect  environment.signal_end_of_episode              , behavior.slot_finish_episode
connect  task.signal_end_of_episode                     , behavior.slot_finish_episode

connect  behavior.signal_end_of_episode                 , logger_eps_return.slot_log
connect  logger_eps_return.slot_log_finished            , logger_action_result.slot_newline
connect  logger_action_result.slot_newline_finished     , lmanager.slot_finish_episode


/// I/O:
connect  rwd_accumulator.out_sum                        , behavior.in_reward

connect  tr_ngnet.out_y                                 , avf_linear.in_feature
connect  lmanager.out_episode_number                    , avf_linear.in_episode_number
connect  avf_linear.out_select_action                   , behavior.in_avf_select_action
connect  avf_linear.out_replacing_trace                 , behavior.in_avf_replacing_trace
connect  avf_linear.out_create_parameter                , behavior.in_avf_create_parameter
connect  avf_linear.out_zero_parameter                  , behavior.in_avf_zero_parameter


connect  behavior.out_return_in_episode                 , logger_eps_return.in_data2

connect  behavior.out_td_error                          , logger_action_result.in_data_real
connect  behavior.out_current_action_value              , logger_action_result.in_data_real


/// parameter setting:

behavior.config={
    UsingEligibilityTrace = true
    UsingReplacingTrace = true
    Alpha = 0.3
    AlphaDecreasingFactor = 0.002
    Gamma = 0.9
    Lambda = 0.9
    GradientMax = 1.0e+100
  }
avf_linear.config={
    ActionSelection = "asBoltzman"
    PolicyImprovement = "piExpReduction"
    // Tau = 5
    // conservative:
    Tau = 0.1
    TauDecreasingFactor = 0.004
    TraceMax = 1.0
  }
