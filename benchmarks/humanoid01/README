Usage:

1. Build:
  $ make

2. Execute as follows:
  $ ./humanoid01.sh -agent m-c/cmn.agent,m-c/disca.agent,m-c/grid.agent -outdir result/rl1/
Some log files are created in result/rl1.
NOTE: result/rl1 should be created by user before execution.

3. Examples:

* Q(lambda)-learning, Grid action space, linear action value function (NGnet):
./humanoid01.sh -agent m-c/cmn.agent,m-c/disca.agent,m-c/grid.agent -outdir result/rl1/

* Q(lambda)-learning, DCOB (action space), linear action value function (NGnet):
./humanoid01.sh -agent m-c/cmn.agent,m-c/disca.agent,m-c/dcob.agent -outdir result/rl1/

* Wire-fitting (random init) updated by Q(lambda)-learning:
./humanoid01.sh -agent m-c/cmn.agent,m-c/wf.agent -outdir result/rl1/

* Wire-fitting (grid init) updated by Q(lambda)-learning:
./humanoid01.sh -agent m-c/cmn.agent,m-c/gwf.agent -outdir result/rl1/

* WF-DCOB, Q(lambda)-learning, linear action value function (NGnet):
./humanoid01.sh -agent m-c/cmn.agent,m-c/wfdcob.agent -outdir result/rl1/

* Fitted Q iteration (updated in every 10 episode), Grid action space, linear action value function (NGnet):
./humanoid01.sh -agent m-c/cmn.agent,m-c/dafqi.agent,m-c/grid.agent -outdir result/rl1/

* LSPI (updated in every 5 episode), Grid action space, linear action value function (NGnet):
./humanoid01.sh -agent m-c/cmn.agent,m-c/dalspi.agent -outdir result/rl1/


* Q(lambda)-learning + Fitted Q iteration (updated in every 10 episode), Grid action space, linear action value function (NGnet):
./humanoid01.sh -agent m-c/cmn.agent,m-c/daqlfqi.agent,m-c/grid.agent -outdir result/rl1/

* Q(lambda)-learning + Fitted Q iteration (updated in every 10 episode), DCOB (action space), linear action value function (NGnet):
./humanoid01.sh -agent m-c/cmn.agent,m-c/daqlfqi.agent,m-c/dcob.agent -outdir result/rl1/

* Q(lambda)-learning + Fitted Q iteration (updated in every 10 episode) for Wire-fitting (grid init):
./humanoid01.sh -agent m-c/cmn.agent,m-c/gwfqlfqi.agent -outdir result/rl1/

* Q(lambda)-learning + Fitted Q iteration (updated in every 10 episode) for WF-DCOB:
./humanoid01.sh -agent m-c/cmn.agent,m-c/wfdcobqlfqi.agent -outdir result/rl1/


* Change the robot's constraint arbitrarily:
  1. Edit the file materials/crawling/dcob.agent:
  original:
    // for crawling/cmn.agent:
    connect  bftrans.signal_execute_command                 , environment.slot_execute_command_des_q
    // for crawling/cmn2.agent:
    // connect  bftrans.signal_execute_command                 , action_converter.slot_x
    // connect  action_converter.signal_y                      , environment.slot_execute_command_des_q
  edited:
    // for crawling/cmn.agent:
    // connect  bftrans.signal_execute_command                 , environment.slot_execute_command_des_q
    // for crawling/cmn2.agent:
    connect  bftrans.signal_execute_command                 , action_converter.slot_x
    connect  action_converter.signal_y                      , environment.slot_execute_command_des_q
  2. Change state_converter and action_converter in the file materials/crawling/cmn2.agent (arbitrarily)
  3. Execute the command:
  ./humanoid01.sh -agent m-c/cmn2.agent,m-c/disca.agent,m-c/dcob.agent -outdir result/rl1/


NOTE: use  '-console true'  option to run in the console mode.



